{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           gene_id    transcript_id  position  label\n",
      "0  ENSG00000004059  ENST00000000233       244      0\n",
      "1  ENSG00000004059  ENST00000000233       261      0\n",
      "2  ENSG00000004059  ENST00000000233       316      0\n",
      "3  ENSG00000004059  ENST00000000233       332      0\n",
      "4  ENSG00000004059  ENST00000000233       368      0\n"
     ]
    }
   ],
   "source": [
    "# parse the labels\n",
    "\n",
    "def parse_labels(label_file_path):\n",
    "    data = []\n",
    "    with open(label_file_path, 'r') as f:\n",
    "        f.readline() # first line is header\n",
    "        for line in f:\n",
    "            gene_id, transcript_id, position, label = line.strip().split(',')\n",
    "            data.append({\n",
    "                'gene_id': gene_id,\n",
    "                'transcript_id': transcript_id,\n",
    "                'position': int(position),\n",
    "                'label': int(label)\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# label_df = parse_labels(\"../data/data.info.labelled\")\n",
    "\n",
    "# export the labels to a csv file\n",
    "# label_df.to_csv('../data/labels.csv', index=False)\n",
    "\n",
    "# print(label_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "0  ENST00000000233       244             AAGACCA             0.00299   \n",
      "1  ENST00000000233       244             AAGACCA             0.00631   \n",
      "2  ENST00000000233       244             AAGACCA             0.00465   \n",
      "3  ENST00000000233       244             AAGACCA             0.00398   \n",
      "4  ENST00000000233       244             AAGACCA             0.00664   \n",
      "\n",
      "   std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "0          2.06             125.0                0.01770            10.40   \n",
      "1          2.53             125.0                0.00844             4.67   \n",
      "2          3.92             109.0                0.01360            12.00   \n",
      "3          2.06             125.0                0.00830             5.01   \n",
      "4          2.92             120.0                0.00266             3.94   \n",
      "\n",
      "   mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \n",
      "0                122.0             0.00930         10.90              84.1  \n",
      "1                126.0             0.01030          6.30              80.9  \n",
      "2                124.0             0.00498          2.13              79.6  \n",
      "3                130.0             0.00498          3.78              80.4  \n",
      "4                129.0             0.01300          7.15              82.2  \n"
     ]
    }
   ],
   "source": [
    "# parse the features\n",
    "\n",
    "def parse_features(feature_file_path):\n",
    "    rows = []\n",
    "\n",
    "    with gzip.open(feature_file_path, 'rt', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "\n",
    "            for transcript_id, positions in data.items():\n",
    "                for position, flanking_data in positions.items():\n",
    "                    for flanking_nucleotide, features_list in flanking_data.items():\n",
    "                        for features in features_list:\n",
    "                            row = {\n",
    "                                \"transcript_id\": transcript_id,\n",
    "                                \"position\": int(position),\n",
    "                                \"flanking_nucleotide\": flanking_nucleotide,\n",
    "                                \"dwelling_time_(-1)\": features[0],\n",
    "                                \"std_dev_(-1)\": features[1],\n",
    "                                \"mean_signal_(-1)\": features[2],\n",
    "                                \"dwelling_time_central\": features[3],\n",
    "                                \"std_dev_central\": features[4],\n",
    "                                \"mean_signal_central\": features[5],\n",
    "                                \"dwelling_time_(+1)\": features[6],\n",
    "                                \"std_dev_(+1)\": features[7],\n",
    "                                \"mean_signal_(+1)\": features[8]\n",
    "                            }\n",
    "                            rows.append(row)  # Append each parsed entry to rows\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# features_df = parse_features(\"../data/dataset0.json.gz\")\n",
    "\n",
    "# print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"../data/features.csv\")\n",
    "label_df = pd.read_csv('../data/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "0  ENST00000000233       244             AAGACCA             0.00299   \n",
      "1  ENST00000000233       244             AAGACCA             0.00631   \n",
      "2  ENST00000000233       244             AAGACCA             0.00465   \n",
      "3  ENST00000000233       244             AAGACCA             0.00398   \n",
      "4  ENST00000000233       244             AAGACCA             0.00664   \n",
      "\n",
      "   std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "0          2.06             125.0                0.01770            10.40   \n",
      "1          2.53             125.0                0.00844             4.67   \n",
      "2          3.92             109.0                0.01360            12.00   \n",
      "3          2.06             125.0                0.00830             5.01   \n",
      "4          2.92             120.0                0.00266             3.94   \n",
      "\n",
      "   mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \n",
      "0                122.0             0.00930         10.90              84.1  \n",
      "1                126.0             0.01030          6.30              80.9  \n",
      "2                124.0             0.00498          2.13              79.6  \n",
      "3                130.0             0.00498          3.78              80.4  \n",
      "4                129.0             0.01300          7.15              82.2  \n",
      "        transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "6041  ENST00000002165        35             AGGACAG              0.0113   \n",
      "6042  ENST00000002165        35             AGGACAG              0.0315   \n",
      "6043  ENST00000002165        35             AGGACAG              0.0116   \n",
      "6044  ENST00000002165        35             AGGACAG              0.0103   \n",
      "6045  ENST00000002165        35             AGGACAG              0.0110   \n",
      "\n",
      "      std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "6041          7.53             114.0                0.01100             6.39   \n",
      "6042          6.04             116.0                0.00830             8.88   \n",
      "6043          7.30             113.0                0.00565             4.62   \n",
      "6044          7.40             117.0                0.00564             7.21   \n",
      "6045          8.55             118.0                0.00598             4.33   \n",
      "\n",
      "      mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \n",
      "6041                119.0             0.00863          4.02              84.9  \n",
      "6042                119.0             0.00437          2.35              81.8  \n",
      "6043                122.0             0.00864          2.68              81.8  \n",
      "6044                118.0             0.00398          1.13              87.4  \n",
      "6045                124.0             0.00693          2.11              81.7  \n",
      "8846267\n",
      "2180839\n"
     ]
    }
   ],
   "source": [
    "# split by genes\n",
    "unique_genes = label_df['gene_id'].unique()\n",
    "train_genes, test_genes = train_test_split(unique_genes, test_size=0.2, random_state=49)\n",
    "\n",
    "# split transcripts based on genes\n",
    "train_transcript = label_df[label_df['gene_id'].isin(train_genes)][\"transcript_id\"]\n",
    "test_transcript = label_df[label_df['gene_id'].isin(test_genes)][\"transcript_id\"]\n",
    "train_df = features_df[features_df['transcript_id'].isin(train_transcript)]\n",
    "test_df = features_df[features_df['transcript_id'].isin(test_transcript)]\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine reads using weighted average\n",
    "\n",
    "'''\n",
    "def weighted_combine_reads(df):\n",
    "    def weighted_avg(group, value_col, weight_col):\n",
    "        d = group[value_col]\n",
    "        w = 1 / (group[weight_col] ** 2)\n",
    "        if w.sum() == 0:\n",
    "            return float('nan')\n",
    "        return (d * w).sum() / w.sum()\n",
    "\n",
    "    grouped = df.groupby(['transcript_id', 'position', 'flanking_nucleotide'])\n",
    "    combined_df = grouped.apply(\n",
    "        lambda group: pd.Series({\n",
    "            'dwelling_time_(-1)': weighted_avg(group, 'dwelling_time_(-1)', 'std_dev_(-1)'),\n",
    "            'mean_signal_(-1)': weighted_avg(group, 'mean_signal_(-1)', 'std_dev_(-1)'),\n",
    "            'mean_range_(-1)': max(group['mean_signal_(-1)']) - min(group['mean_signal_(-1)']),\n",
    "            'dwelling_time_central': weighted_avg(group, 'dwelling_time_central', 'std_dev_central'),\n",
    "            'mean_signal_central': weighted_avg(group, 'mean_signal_central', 'std_dev_central'),\n",
    "            'mean_range_central': max(group['mean_signal_central']) - min(group['mean_signal_central']),\n",
    "            'dwelling_time_(+1)': weighted_avg(group, 'dwelling_time_(+1)', 'std_dev_(+1)'),\n",
    "            'mean_signal_(+1)': weighted_avg(group, 'mean_signal_(+1)', 'std_dev_(+1)'),\n",
    "            'mean_range_(+1)': max(group['mean_signal_(+1)']) - min(group['mean_signal_(+1)'])\n",
    "        }), include_groups=False\n",
    "    ).reset_index()\n",
    "\n",
    "    # Explicitly include grouping columns to avoid warnings\n",
    "    combined_df = combined_df[['transcript_id', 'position', 'flanking_nucleotide', \n",
    "                               'dwelling_time_(-1)', 'mean_signal_(-1)', 'mean_range_(-1)', \n",
    "                               'dwelling_time_central', 'mean_signal_central', 'mean_range_central', \n",
    "                               'dwelling_time_(+1)', 'mean_signal_(+1)', 'mean_range_(+1)']]\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "train_combined_weighted = weighted_combine_reads(train_df)\n",
    "test_combined_weighted = weighted_combine_reads(test_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "0  ENST00000000233       244             AAGACCA            0.008264   \n",
      "1  ENST00000000233       261             CAAACTG            0.006609   \n",
      "2  ENST00000000233       316             GAAACAG            0.007570   \n",
      "3  ENST00000000233       332             AGAACAT            0.010620   \n",
      "4  ENST00000000233       368             AGGACAA            0.010701   \n",
      "\n",
      "   std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "0      4.223784        123.702703               0.009373         7.382162   \n",
      "1      3.216424        109.681395               0.006813         3.226535   \n",
      "2      2.940541        105.475676               0.007416         3.642703   \n",
      "3      6.476350        129.355000               0.008632         2.899200   \n",
      "4      6.415051        117.924242               0.011479         5.870303   \n",
      "\n",
      "   mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \n",
      "0           125.913514            0.007345      4.386989         80.570270  \n",
      "1           107.889535            0.007710      3.016599         94.290698  \n",
      "2            98.947027            0.007555      2.087146         89.364324  \n",
      "3            97.836500            0.006101      2.236520         89.154000  \n",
      "4           121.954545            0.010019      4.260253         85.178788  \n",
      "     transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "0  ENST00000001008       190             ATGACAG            0.005804   \n",
      "1  ENST00000001008       257             TGGACAT            0.008548   \n",
      "2  ENST00000001008       270             CAAACAG            0.006679   \n",
      "3  ENST00000001008       338             GGGACCG            0.008288   \n",
      "4  ENST00000001008       389             TTGACTC            0.009172   \n",
      "\n",
      "   std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "0      5.289111         87.924444               0.007943         9.721111   \n",
      "1      3.990641        117.224359               0.009150         7.705192   \n",
      "2      2.538335        104.950610               0.006591         3.574207   \n",
      "3      4.246859        116.576923               0.007515         6.931923   \n",
      "4      2.986500        106.193750               0.007836         7.751188   \n",
      "\n",
      "   mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \n",
      "0           112.928889            0.007406      2.419630         81.121481  \n",
      "1           118.500000            0.006982      3.795064         81.173718  \n",
      "2            97.921951            0.006632      2.704756         87.333537  \n",
      "3           119.987179            0.009405      2.683526         78.469231  \n",
      "4           118.700000            0.006973      3.190119         86.410000  \n"
     ]
    }
   ],
   "source": [
    "# combine reads using average\n",
    "train_combined = train_df.groupby(['transcript_id', 'position', 'flanking_nucleotide']).mean().reset_index()\n",
    "test_combined = test_df.groupby(['transcript_id', 'position', 'flanking_nucleotide']).mean().reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(train_combined.head())\n",
    "print(test_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "0  ENST00000000233       244             AAGACCA            0.008264   \n",
      "1  ENST00000000233       261             CAAACTG            0.006609   \n",
      "2  ENST00000000233       316             GAAACAG            0.007570   \n",
      "3  ENST00000000233       332             AGAACAT            0.010620   \n",
      "4  ENST00000000233       368             AGGACAA            0.010701   \n",
      "\n",
      "   std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "0      4.223784        123.702703               0.009373         7.382162   \n",
      "1      3.216424        109.681395               0.006813         3.226535   \n",
      "2      2.940541        105.475676               0.007416         3.642703   \n",
      "3      6.476350        129.355000               0.008632         2.899200   \n",
      "4      6.415051        117.924242               0.011479         5.870303   \n",
      "\n",
      "   mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \\\n",
      "0           125.913514            0.007345      4.386989         80.570270   \n",
      "1           107.889535            0.007710      3.016599         94.290698   \n",
      "2            98.947027            0.007555      2.087146         89.364324   \n",
      "3            97.836500            0.006101      2.236520         89.154000   \n",
      "4           121.954545            0.010019      4.260253         85.178788   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "     transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "0  ENST00000001008       190             ATGACAG            0.005804   \n",
      "1  ENST00000001008       257             TGGACAT            0.008548   \n",
      "2  ENST00000001008       270             CAAACAG            0.006679   \n",
      "3  ENST00000001008       338             GGGACCG            0.008288   \n",
      "4  ENST00000001008       389             TTGACTC            0.009172   \n",
      "\n",
      "   std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "0      5.289111         87.924444               0.007943         9.721111   \n",
      "1      3.990641        117.224359               0.009150         7.705192   \n",
      "2      2.538335        104.950610               0.006591         3.574207   \n",
      "3      4.246859        116.576923               0.007515         6.931923   \n",
      "4      2.986500        106.193750               0.007836         7.751188   \n",
      "\n",
      "   mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \\\n",
      "0           112.928889            0.007406      2.419630         81.121481   \n",
      "1           118.500000            0.006982      3.795064         81.173718   \n",
      "2            97.921951            0.006632      2.704756         87.333537   \n",
      "3           119.987179            0.009405      2.683526         78.469231   \n",
      "4           118.700000            0.006973      3.190119         86.410000   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n"
     ]
    }
   ],
   "source": [
    "# merge data with labels\n",
    "train_labelled = pd.merge(train_combined, label_df[['transcript_id', 'position', 'label']], \n",
    "                     on=['transcript_id', 'position'], \n",
    "                     how='left')\n",
    "\n",
    "test_labelled = pd.merge(test_combined, label_df[['transcript_id', 'position', 'label']],\n",
    "                    on=['transcript_id', 'position'],\n",
    "                    how='left')\n",
    "\n",
    "print(train_labelled.head())\n",
    "print(test_labelled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use random oversampling here instead of SMOTE because it could generate synthetic transcript IDs and positions, which are not valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185164\n"
     ]
    }
   ],
   "source": [
    "X = train_labelled.drop('label', axis=1)  # Features\n",
    "y = train_labelled['label']               # Target (label)\n",
    "\n",
    "# Define the oversampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Apply oversampling\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Combine the resampled features and labels into a new DataFrame\n",
    "resampled_train_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='label')], axis=1)\n",
    "\n",
    "# Display the new shape of the resampled dataset\n",
    "print(len(resampled_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "0  ENST00000000233       244             AAGACCA            0.088436   \n",
      "1  ENST00000000233       261             CAAACTG           -0.838156   \n",
      "2  ENST00000000233       316             GAAACAG           -0.300297   \n",
      "3  ENST00000000233       332             AGAACAT            1.407322   \n",
      "4  ENST00000000233       368             AGGACAA            1.452251   \n",
      "\n",
      "   std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "0     -0.061855          1.138815               0.739554         1.020961   \n",
      "1     -0.582332         -0.101667              -0.778025        -0.883882   \n",
      "2     -0.724875         -0.473752              -0.420844        -0.693121   \n",
      "3      1.101990          1.638881               0.300377        -1.033925   \n",
      "4      1.070318          0.627588               1.987836         0.327959   \n",
      "\n",
      "   mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \\\n",
      "0             1.199076            0.220984      1.576897         -1.143439   \n",
      "1            -0.246131            0.502809      0.045775          1.634903   \n",
      "2            -0.963164            0.383174     -0.992693          0.637328   \n",
      "3            -1.052209           -0.738115     -0.825799          0.594738   \n",
      "4             0.881636            2.283601      1.435295         -0.210230   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "     transcript_id  position flanking_nucleotide  dwelling_time_(-1)  \\\n",
      "0  ENST00000001008       190             ATGACAG           -1.290941   \n",
      "1  ENST00000001008       257             TGGACAT            0.243875   \n",
      "2  ENST00000001008       270             CAAACAG           -0.801456   \n",
      "3  ENST00000001008       338             GGGACCG            0.098271   \n",
      "4  ENST00000001008       389             TTGACTC            0.592624   \n",
      "\n",
      "   std_dev_(-1)  mean_signal_(-1)  dwelling_time_central  std_dev_central  \\\n",
      "0      0.491055         -2.020922              -0.111843         2.075580   \n",
      "1     -0.178467          0.587086               0.593009         1.156565   \n",
      "2     -0.927310         -0.505410              -0.900928        -0.726663   \n",
      "3     -0.046355          0.529457              -0.361164         0.804048   \n",
      "4     -0.696226         -0.394757              -0.174312         1.177534   \n",
      "\n",
      "   mean_signal_central  dwelling_time_(+1)  std_dev_(+1)  mean_signal_(+1)  \\\n",
      "0             0.163753            0.275508     -0.615380         -1.019357   \n",
      "1             0.612472           -0.052187      0.928450         -1.008767   \n",
      "2            -1.044965           -0.322977     -0.295345          0.239960   \n",
      "3             0.732255            1.821331     -0.319175         -1.557025   \n",
      "4             0.628581           -0.059578      0.249441          0.052740   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "'''\n",
    "# weighted avg combined reads\n",
    "numeric_columns = ['dwelling_time_(-1)', 'mean_signal_(-1)', 'mean_range_(-1)',\n",
    "                   'dwelling_time_central', 'mean_signal_central', 'mean_range_central',\n",
    "                   'dwelling_time_(+1)', 'mean_signal_(+1)', 'mean_range_(+1)']\n",
    "'''\n",
    "\n",
    "# avg combined reads\n",
    "numeric_columns = ['dwelling_time_(-1)', 'std_dev_(-1)', 'mean_signal_(-1)',\n",
    "                   'dwelling_time_central', 'std_dev_central', 'mean_signal_central',\n",
    "                   'dwelling_time_(+1)', 'std_dev_(+1)', 'mean_signal_(+1)']\n",
    "\n",
    "# scale the numeric columns of train and test data\n",
    "# standardized_train_df = resampled_train_df.copy()\n",
    "standardized_train_df = train_labelled.copy()\n",
    "standardized_train_df[numeric_columns] = scaler.fit_transform(train_labelled[numeric_columns])\n",
    "\n",
    "standardized_test_df = test_labelled.copy()\n",
    "standardized_test_df[numeric_columns] = scaler.fit_transform(test_labelled[numeric_columns])\n",
    "\n",
    "# View the standardized dataset\n",
    "print(standardized_train_df.head())\n",
    "print(standardized_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear all variables in the workspace\n",
    "# %reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# train = pd.read_csv('../data/train_oversampled.csv')\n",
    "# test = pd.read_csv('../data/test_oversampled.csv')\n",
    "\n",
    "# drop rows with NaN values\n",
    "test = test.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
